{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061a4fcc-7322-4fb8-82db-4a5c664b7079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working great\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from deepface import DeepFace\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Function to detect age, gender, and emotion using DeepFace\n",
    "def detect_attributes(frame):\n",
    "    result = DeepFace.analyze(frame, actions=['age', 'gender', 'emotion'], enforce_detection=False)\n",
    "    return result[0] if isinstance(result, list) else result\n",
    "\n",
    "# Function to update the displayed image with detected attributes\n",
    "def update_frame():\n",
    "    ret, frame = cap.read()  # Capture frame from webcam\n",
    "    if ret:\n",
    "        result = detect_attributes(frame)  # Detect attributes using DeepFace\n",
    "        # Format the detected attributes for display\n",
    "        age_gender_emotion = \"Age: {}, Gender: {}, Emotion: {}\".format(\n",
    "            result.get('age', 'Unknown'), \n",
    "            result.get('gender', 'Unknown'), \n",
    "            result.get('dominant_emotion', 'Unknown')\n",
    "        )\n",
    "\n",
    "        # Display the frame with detected attributes in the GUI\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = ImageTk.PhotoImage(image=Image.fromarray(frame))\n",
    "        label.config(image=img)\n",
    "        label.image = img\n",
    "\n",
    "        # Display the detected attributes below the frame\n",
    "        text.config(text=age_gender_emotion)\n",
    "    # Schedule the next frame update\n",
    "    label.after(10, update_frame)\n",
    "\n",
    "# Create a tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Facial Attributes Detection\")\n",
    "\n",
    "# Create a label for displaying the webcam feed\n",
    "label = tk.Label(root)\n",
    "label.pack()\n",
    "\n",
    "# Create a label for displaying detected attributes\n",
    "text = tk.Label(root, font=('Helvetica', 14))\n",
    "text.pack()\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Start updating the frame\n",
    "update_frame()\n",
    "\n",
    "# Run the GUI loop\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c63cf3a3-cc75-41a6-9376-bd07bfe70319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender dictionary: {'Woman': 0.39988625794649124, 'Man': 99.60010647773743}\n",
      "Male percentage: 0\n",
      "Female percentage: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender dictionary: {'Woman': 0.4218459129333496, 'Man': 99.57815408706665}\n",
      "Male percentage: 0\n",
      "Female percentage: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender dictionary: {'Woman': 0.6582405418157578, 'Man': 99.34176206588745}\n",
      "Male percentage: 0\n",
      "Female percentage: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender dictionary: {'Woman': 0.4249781370162964, 'Man': 99.57501888275146}\n",
      "Male percentage: 0\n",
      "Female percentage: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender dictionary: {'Woman': 0.8955424651503563, 'Man': 99.10446405410767}\n",
      "Male percentage: 0\n",
      "Female percentage: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender dictionary: {'Woman': 0.7536936551332474, 'Man': 99.24629926681519}\n",
      "Male percentage: 0\n",
      "Female percentage: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 3/3 [00:01<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender dictionary: {'Woman': 0.46436041593551636, 'Man': 99.53563809394836}\n",
      "Male percentage: 0\n",
      "Female percentage: 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from deepface import DeepFace\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Function to detect age, gender, and emotion using DeepFace\n",
    "def detect_attributes(frame):\n",
    "    result = DeepFace.analyze(frame, actions=['age', 'gender', 'emotion'], enforce_detection=False)\n",
    "    return result[0] if isinstance(result, list) else result\n",
    "\n",
    "# Function to update the displayed image with detected attributes\n",
    "def update_frame():\n",
    "    ret, frame = cap.read()  # Capture frame from webcam\n",
    "    if ret:\n",
    "        result = detect_attributes(frame)  # Detect attributes using DeepFace\n",
    "        \n",
    "        # Get gender information from the result dictionary\n",
    "        gender = result.get('gender', {})\n",
    "        print(\"Gender dictionary:\", gender)\n",
    "        male_percentage = gender.get('male', 0) * 100\n",
    "        female_percentage = gender.get('female', 0) * 100\n",
    "        print(\"Male percentage:\", male_percentage)\n",
    "        print(\"Female percentage:\", female_percentage)\n",
    "        \n",
    "        # Format the detected attributes for display\n",
    "        age_gender_emotion = \"Age: {}, Gender: {:.2f}% Male, {:.2f}% Female, Emotion: {}\".format(\n",
    "            result.get('age', 'Unknown'), \n",
    "            male_percentage, \n",
    "            female_percentage, \n",
    "            result.get('dominant_emotion', 'Unknown')\n",
    "        )\n",
    "\n",
    "        # Display the frame with detected attributes in the GUI\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = ImageTk.PhotoImage(image=Image.fromarray(frame))\n",
    "        label.config(image=img)\n",
    "        label.image = img\n",
    "\n",
    "        # Display the detected attributes below the frame\n",
    "        text.config(text=age_gender_emotion)\n",
    "    # Schedule the next frame update\n",
    "    root.after(10, update_frame)\n",
    "\n",
    "# Create a tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Facial Attributes Detection\")\n",
    "\n",
    "# Create a label for displaying the webcam feed\n",
    "label = tk.Label(root)\n",
    "label.pack()\n",
    "\n",
    "# Create a label for displaying detected attributes\n",
    "text = tk.Label(root, font=('Helvetica', 14))\n",
    "text.pack()\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Start updating the frame\n",
    "update_frame()\n",
    "\n",
    "# Run the GUI loop\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342f1b3-8e57-4795-a866-fda2d8c7f2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:01<00:00,  2.25it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:01<00:00,  2.48it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:01<00:00,  2.29it/s]\n",
      "Action: emotion:  67%|██████▋   | 2/3 [00:01<00:00,  1.81it/s]"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from deepface import DeepFace\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Function to detect age, gender, and emotion using DeepFace\n",
    "def detect_attributes(frame):\n",
    "    result = DeepFace.analyze(frame, actions=['age', 'gender', 'emotion'], enforce_detection=False)\n",
    "    return result[0] if isinstance(result, list) else result\n",
    "\n",
    "# Function to update the displayed image with detected attributes\n",
    "def update_frame():\n",
    "    ret, frame = cap.read()  # Capture frame from webcam\n",
    "    if ret:\n",
    "        result = detect_attributes(frame)  # Detect attributes using DeepFace\n",
    "        \n",
    "        # Get gender information from the result dictionary\n",
    "        gender = result.get('gender', {})\n",
    "        male_percentage = gender.get('Man', 0)\n",
    "        female_percentage = gender.get('Woman', 0)\n",
    "        \n",
    "        # Format the detected attributes for display\n",
    "        age_gender_emotion = \"Age: {}, Male: {:.2f}% , Female {:.2f}% ,Emotion: {}\".format(\n",
    "            result.get('age', 'Unknown'), \n",
    "            male_percentage, \n",
    "            female_percentage, \n",
    "            result.get('dominant_emotion', 'Unknown')\n",
    "        )\n",
    "\n",
    "        # Display the frame with detected attributes in the GUI\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = ImageTk.PhotoImage(image=Image.fromarray(frame))\n",
    "        label.config(image=img)\n",
    "        label.image = img\n",
    "\n",
    "        # Display the detected attributes below the frame\n",
    "        text.config(text=age_gender_emotion)\n",
    "    # Schedule the next frame update\n",
    "    root.after(10, update_frame)\n",
    "\n",
    "# Create a tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Facial Attributes Detection\")\n",
    "\n",
    "# Create a label for displaying the webcam feed\n",
    "label = tk.Label(root)\n",
    "label.pack()\n",
    "\n",
    "# Create a label for displaying detected attributes\n",
    "text = tk.Label(root, font=('Helvetica', 14))\n",
    "text.pack()\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Start updating the frame\n",
    "update_frame()\n",
    "\n",
    "# Run the GUI loop\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2791f-3f0f-48cc-8ffe-06e2a538d989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
